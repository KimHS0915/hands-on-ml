{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "needed-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-gauge",
   "metadata": {},
   "source": [
    "Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constant-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proper-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disciplinary-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 829us/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 472us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "twenty-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dangerous-utility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38856643],\n",
       "       [1.6792021 ],\n",
       "       [3.1022794 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-growth",
   "metadata": {},
   "source": [
    "Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intellectual-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bibliographic-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blocked-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "temporal-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 1.2611 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.6580 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.5878 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.5582 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.5347 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.5158 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.5002 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4876 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4760 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4659 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.4577 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.4498 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.4428 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4366 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.4307 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.4257 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.4210 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4167 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 586us/step - loss: 0.4121 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.4088 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 410us/step - loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amended-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guided-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minor-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 798us/step - loss: 1.8145 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.6771 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.5979 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.5584 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.5334 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.5120 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.4970 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.4843 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.4730 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.4644 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.4570 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4510 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.4462 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4421 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.4385 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4356 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.4322 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.4305 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4274 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.4261 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 429us/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, \n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "physical-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "greatest-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fifth-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adolescent-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1000us/step - loss: 2.1365 - main_output_loss: 1.9196 - aux_output_loss: 4.0890 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.8905 - main_output_loss: 0.6969 - aux_output_loss: 2.6326 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.7429 - main_output_loss: 0.6088 - aux_output_loss: 1.9499 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.6771 - main_output_loss: 0.5691 - aux_output_loss: 1.6485 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.6381 - main_output_loss: 0.5434 - aux_output_loss: 1.4911 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.6079 - main_output_loss: 0.5207 - aux_output_loss: 1.3923 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.5853 - main_output_loss: 0.5040 - aux_output_loss: 1.3175 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.5666 - main_output_loss: 0.4898 - aux_output_loss: 1.2572 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.5504 - main_output_loss: 0.4771 - aux_output_loss: 1.2101 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.5373 - main_output_loss: 0.4671 - aux_output_loss: 1.1695 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.5266 - main_output_loss: 0.4591 - aux_output_loss: 1.1344 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.5173 - main_output_loss: 0.4520 - aux_output_loss: 1.1048 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.5095 - main_output_loss: 0.4465 - aux_output_loss: 1.0765 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.5027 - main_output_loss: 0.4417 - aux_output_loss: 1.0511 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.4967 - main_output_loss: 0.4376 - aux_output_loss: 1.0280 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.4916 - main_output_loss: 0.4343 - aux_output_loss: 1.0070 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.4867 - main_output_loss: 0.4311 - aux_output_loss: 0.9872 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4829 - main_output_loss: 0.4289 - aux_output_loss: 0.9686 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4785 - main_output_loss: 0.4260 - aux_output_loss: 0.9510 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4756 - main_output_loss: 0.4246 - aux_output_loss: 0.9344 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                   validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gross-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 516us/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-painting",
   "metadata": {},
   "source": [
    "The subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adjusted-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hairy-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(30, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "raising-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3298 - output_1_loss: 2.2186 - output_2_loss: 3.3304 - val_loss: 2.1435 - val_output_1_loss: 1.1581 - val_output_2_loss: 11.0117\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.9714 - output_1_loss: 0.8543 - output_2_loss: 2.0252 - val_loss: 1.7567 - val_output_1_loss: 0.8205 - val_output_2_loss: 10.1825\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.8268 - output_1_loss: 0.7289 - output_2_loss: 1.7082 - val_loss: 1.5664 - val_output_1_loss: 0.7913 - val_output_2_loss: 8.5419\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 727us/step - loss: 0.7636 - output_1_loss: 0.6764 - output_2_loss: 1.5477 - val_loss: 1.3088 - val_output_1_loss: 0.6549 - val_output_2_loss: 7.1933\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.7211 - output_1_loss: 0.6402 - output_2_loss: 1.4489 - val_loss: 1.1357 - val_output_1_loss: 0.5964 - val_output_2_loss: 5.9898\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.6895 - output_1_loss: 0.6124 - output_2_loss: 1.3833 - val_loss: 1.0036 - val_output_1_loss: 0.5937 - val_output_2_loss: 4.6933\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.6632 - output_1_loss: 0.5894 - output_2_loss: 1.3274 - val_loss: 0.8904 - val_output_1_loss: 0.5591 - val_output_2_loss: 3.8714\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.6410 - output_1_loss: 0.5701 - output_2_loss: 1.2796 - val_loss: 0.8009 - val_output_1_loss: 0.5243 - val_output_2_loss: 3.2903\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.6204 - output_1_loss: 0.5514 - output_2_loss: 1.2416 - val_loss: 0.7357 - val_output_1_loss: 0.5144 - val_output_2_loss: 2.7275\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.6024 - output_1_loss: 0.5355 - output_2_loss: 1.2043 - val_loss: 0.6849 - val_output_1_loss: 0.5014 - val_output_2_loss: 2.3370\n",
      "162/162 [==============================] - 0s 497us/step - loss: 0.5841 - output_1_loss: 0.5188 - output_2_loss: 1.1722\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000158BEABE288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10, \n",
    "                     validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-enforcement",
   "metadata": {},
   "source": [
    "Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "british-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assured-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "quantitative-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 715us/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 586us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 580us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 410us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neural-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fifteen-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "looking-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000158BEA263A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5400236],\n",
       "       [1.6505971],\n",
       "       [3.0098243]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "matched-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "clinical-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x158bd7d7608>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-bloom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hands] *",
   "language": "python",
   "name": "conda-env-hands-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
