{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defensive-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satellite-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-riding",
   "metadata": {},
   "source": [
    "Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "close-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.6499 - val_loss: 0.4175\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4631 - val_loss: 0.3865\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.3984 - val_loss: 0.3760\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.4053 - val_loss: 0.3592\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 586us/step - loss: 0.3957 - val_loss: 0.5137\n",
      "162/162 [==============================] - 0s 404us/step - loss: 0.5237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5236707329750061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer,\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=5, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saving-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=[batch_input_shape[-1], self.units], \n",
    "                                      initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(name='bias', \n",
    "                                    shape=[self.units], \n",
    "                                    initializer='zeros')\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units': self.units, \n",
    "                'activation': keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secondary-century",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 823us/step - loss: 1.5019 - val_loss: 1.2678\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.5459 - val_loss: 0.4559\n",
      "162/162 [==============================] - 0s 404us/step - loss: 0.4758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47581905126571655"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation='relu', input_shape=input_shape),\n",
    "    MyDense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_with_custom_layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model_with_custom_layer.h5', \n",
    "                                custom_objects={'MyDense': MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        x1, x2 = x\n",
    "        return x1 + x2, x1 * x2\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordered-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deadly-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "found-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled_a, x_train_scaled_b = split_data(x_train_scaled)\n",
    "x_valid_scaled_a, x_valid_scaled_b = split_data(x_valid_scaled)\n",
    "x_test_scaled_a, x_test_scaled_b = split_data(x_test_scaled)\n",
    "\n",
    "x_train_scaled_a.shape, x_train_scaled_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bigger-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=x_train_scaled_a.shape[-1])\n",
    "input_b = keras.layers.Input(shape=x_train_scaled_b.shape[-1])\n",
    "hidden_a, hidden_b = MyMultiLayer()((input_a, input_b))\n",
    "hidden_a = keras.layers.Dense(30, activation='selu')(hidden_a)\n",
    "hidden_b = keras.layers.Dense(30, activation='selu')(hidden_b)\n",
    "concat = keras.layers.Concatenate()((hidden_a, hidden_b))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_a, input_b], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "parallel-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 854us/step - loss: 1.8849 - val_loss: 4.0209\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 702us/step - loss: 1.0073 - val_loss: 0.9525\n",
      "162/162 [==============================] - 0s 429us/step - loss: 1.0414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0413503646850586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit((x_train_scaled_a, x_train_scaled_b), y_train, epochs=2, \n",
    "          validation_data=((x_valid_scaled_a, x_valid_scaled_b), y_valid))\n",
    "\n",
    "model.evaluate((x_test_scaled_a, x_test_scaled_b), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "governing-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(x), stddev=self.stddev)\n",
    "            return x + noise\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "foreign-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation='selu'),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "heavy-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 760us/step - loss: 2.4692 - val_loss: 0.9278\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 674us/step - loss: 1.0058 - val_loss: 0.7988\n",
      "162/162 [==============================] - 0s 416us/step - loss: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7787245512008667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-student",
   "metadata": {},
   "source": [
    "Custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "careful-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_scaled = x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minus-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation='elu', \n",
    "                                          kernel_initializer='he_normal')\n",
    "                       for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "latin-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation='elu', \n",
    "                                          kernel_initializer='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moved-beads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 989us/step - loss: 8.1168\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 884us/step - loss: 1.7072\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 829us/step - loss: 1.3773\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 854us/step - loss: 1.2679\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.9363\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unlike-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 528us/step - loss: 0.6157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6156613826751709"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test_scaled, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worthy-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07981298],\n",
       "       [1.8383291 ],\n",
       "       [4.5888257 ],\n",
       "       ...,\n",
       "       [1.5495952 ],\n",
       "       [2.7323132 ],\n",
       "       [4.211289  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_new_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "given-behavior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_8_layer_call_and_return_conditional_losses, dense_8_layer_call_fn, dense_9_layer_call_and_return_conditional_losses, dense_9_layer_call_fn, dense_10_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_model.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_model.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('custom_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stable-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('custom_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "corrected-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 887us/step - loss: 0.7770\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.9922\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.4034\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.7274\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.8868\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ambient-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 653us/step - loss: 1.3901\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.6113\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4894\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.6447\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.4279\n"
     ]
    }
   ],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', \n",
    "                       kernel_initializer='he_normal'),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stable-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 441us/step - loss: 0.4446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4446283280849457"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test_scaled, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excellent-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6536274],\n",
       "       [1.8239018],\n",
       "       [3.635159 ],\n",
       "       ...,\n",
       "       [1.3967994],\n",
       "       [2.6738923],\n",
       "       [4.203689 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_new_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "productive-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation='selu', \n",
    "                                          kernel_initializer='lecun_normal')\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruct = keras.layers.Dense(8)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name='reconstruction_error')\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        self.recon_loss = 0.05 * tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        \n",
    "        if training:\n",
    "            result = self.reconstruction(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=[self.recon_loss])\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        return {m.name: m.result() for m in self.metrics}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ongoing-approval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 699us/step - loss: 0.7098 - reconstruction_error: 0.0000e+00\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.4665 - reconstruction_error: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(x_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "little-manual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79058826],\n",
       "       [1.8234769 ],\n",
       "       [3.8583977 ],\n",
       "       ...,\n",
       "       [1.6587366 ],\n",
       "       [2.3147085 ],\n",
       "       [3.9397335 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
