{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inclusive-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entertaining-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-reporter",
   "metadata": {},
   "source": [
    "Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "significant-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contrary-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.7242 - val_loss: 0.4193\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.4501 - val_loss: 0.3872\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.4221 - val_loss: 0.3577\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.3905 - val_loss: 0.3630\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.3822 - val_loss: 0.3500\n",
      "162/162 [==============================] - 0s 366us/step - loss: 0.3632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3632471561431885"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer,\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=5, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cognitive-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "irish-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=[batch_input_shape[-1], self.units], \n",
    "                                      initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(name='bias', \n",
    "                                    shape=[self.units], \n",
    "                                    initializer='zeros')\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units': self.units, \n",
    "                'activation': keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fourth-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 754us/step - loss: 1.8547 - val_loss: 0.7400\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.5631 - val_loss: 0.5488\n",
      "162/162 [==============================] - 0s 373us/step - loss: 0.4829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4828752279281616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation='relu', input_shape=input_shape),\n",
    "    MyDense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romantic-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_with_custom_layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "german-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model_with_custom_layer.h5', \n",
    "                                custom_objects={'MyDense': MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brief-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        x1, x2 = x\n",
    "        return x1 + x2, x1 * x2\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "apparent-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "proud-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "durable-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled_a, x_train_scaled_b = split_data(x_train_scaled)\n",
    "x_valid_scaled_a, x_valid_scaled_b = split_data(x_valid_scaled)\n",
    "x_test_scaled_a, x_test_scaled_b = split_data(x_test_scaled)\n",
    "\n",
    "x_train_scaled_a.shape, x_train_scaled_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wound-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=x_train_scaled_a.shape[-1])\n",
    "input_b = keras.layers.Input(shape=x_train_scaled_b.shape[-1])\n",
    "hidden_a, hidden_b = MyMultiLayer()((input_a, input_b))\n",
    "hidden_a = keras.layers.Dense(30, activation='selu')(hidden_a)\n",
    "hidden_b = keras.layers.Dense(30, activation='selu')(hidden_b)\n",
    "concat = keras.layers.Concatenate()((hidden_a, hidden_b))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_a, input_b], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "competitive-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 840us/step - loss: 1.7525 - val_loss: 3.2921\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.9619 - val_loss: 1.9505\n",
      "162/162 [==============================] - 0s 404us/step - loss: 1.0700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.069963812828064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit((x_train_scaled_a, x_train_scaled_b), y_train, epochs=2, \n",
    "          validation_data=((x_valid_scaled_a, x_valid_scaled_b), y_valid))\n",
    "\n",
    "model.evaluate((x_test_scaled_a, x_test_scaled_b), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pacific-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(x), stddev=self.stddev)\n",
    "            return x + noise\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fewer-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation='selu'),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "streaming-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 732us/step - loss: 2.2520 - val_loss: 1.7259\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 602us/step - loss: 1.0289 - val_loss: 0.7799\n",
      "162/162 [==============================] - 0s 379us/step - loss: 0.7768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7768131494522095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-restaurant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
