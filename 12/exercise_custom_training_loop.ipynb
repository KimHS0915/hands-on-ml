{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "social-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-departure",
   "metadata": {},
   "source": [
    "Exercise 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_teset) = fashion_mnist.load_data()\n",
    "\n",
    "x_train_full = x_train_full.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "\n",
    "x_train, x_valid = x_train_full[5000:], x_train_full[:5000]\n",
    "y_train, y_valid = y_train_full[5000:], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-grant",
   "metadata": {},
   "source": [
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "further-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "planned-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(x, y, batch_size=32):\n",
    "    idx = np.random.randint(len(x), size=batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "\n",
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = '>' if running else '='\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = '{{:-{}d}}/{{}} [{{}}]'.format(len(str(total)))\n",
    "    params = [iteration, total, '=' * p + c + '.' * (size - p - 1)]\n",
    "    return fmt.format(*params)\n",
    "\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = ' - '.join([\"{}: {:.4f}\".format(m.name, m.result()) \n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = '' if iteration < total else '\\n'\n",
    "    print('\\r{} - {}'.format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operational-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(x_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mysterious-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55000/55000 [==============================] - mean: 0.5098 - sparse_categorical_accuracy: 0.8184\n",
      "\t\t\t\t\t\tval_loss: 0.4200 - val_accuracy: 0.8516\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - mean: 0.4105 - sparse_categorical_accuracy: 0.8518\n",
      "\t\t\t\t\t\tval_loss: 0.3973 - val_accuracy: 0.8596\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - mean: 0.3825 - sparse_categorical_accuracy: 0.8630\n",
      "\t\t\t\t\t\tval_loss: 0.4346 - val_accuracy: 0.8558\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - mean: 0.3746 - sparse_categorical_accuracy: 0.8668\n",
      "\t\t\t\t\t\tval_loss: 0.4037 - val_accuracy: 0.8654\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - mean: 0.3542 - sparse_categorical_accuracy: 0.8724\n",
      "\t\t\t\t\t\tval_loss: 0.4282 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        x_batch, y_batch = random_batch(x_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    y_pred = model(x_valid)\n",
    "    val_loss = np.mean(loss_fn(y_valid, y_pred))\n",
    "    val_acc = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "    print(f'\\t\\t\\t\\t\\t\\tval_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}')\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smooth-correspondence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566651b88dab45608790a97a5ef23f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff043064384d00a88b7f30b0450080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6ed33f1c1b40098416aabfe5566491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74155fde3455463cb7360ad64325ca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222908dc488944f4b3cd59e3ab1c6d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0794f0e70bf4d6fbbf6360078a6d03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc='Epoch {}/{}'.format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    x_batch, y_batch = random_batch(x_train, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(x_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))\n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status['loss'] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "                y_pred = model(x_valid)\n",
    "                status['val_loss'] = np.mean(loss_fn(y_valid, y_pred))\n",
    "                status['val_accuracy'] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "                steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print('To run this cell, please install tqdm, ipywidgets and restart jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-quantity",
   "metadata": {},
   "source": [
    "b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indonesian-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "])\n",
    "\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers,\n",
    "    upper_layers,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "treated-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aware-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55000/55000 [==============================] - mean: 1.0455 - sparse_categorical_accuracy: 0.6922\n",
      "\t\t\t\t\t\tval_loss: 0.6891 - val_accuracy: 0.7828\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - mean: 0.6463 - sparse_categorical_accuracy: 0.7814\n",
      "\t\t\t\t\t\tval_loss: 0.5901 - val_accuracy: 0.8016\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - mean: 0.5852 - sparse_categorical_accuracy: 0.7980\n",
      "\t\t\t\t\t\tval_loss: 0.5508 - val_accuracy: 0.8144\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - mean: 0.5541 - sparse_categorical_accuracy: 0.8107\n",
      "\t\t\t\t\t\tval_loss: 0.5264 - val_accuracy: 0.8204\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - mean: 0.5338 - sparse_categorical_accuracy: 0.8140\n",
      "\t\t\t\t\t\tval_loss: 0.5117 - val_accuracy: 0.8254\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        x_batch, y_batch = random_batch(x_train, y_train)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        for layers, optimizer in ((lower_layers, lower_optimizer), \n",
    "                                  (upper_layers, upper_optimizer)):\n",
    "            gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "        del tape\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    y_pred = model(x_valid)\n",
    "    val_loss = np.mean(loss_fn(y_valid, y_pred))\n",
    "    val_acc = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "        tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "    print(f'\\t\\t\\t\\t\\t\\tval_loss: {val_loss:.4f} - val_accuracy: {val_acc:.4f}')\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bridal-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1327e4755540497f955c70d187028b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd03fdeb7bc426a9c8ff83d84a4b308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73193a0f01374ac8a7bce5cd28fcac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb39ab9b7ad3428e99b1972ef69e96ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730fa736e75a4c38a0120ee7993c1b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0f5a97eae54621b8fa787d0d6378f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc='Epoch {}/{}'.format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    x_batch, y_batch = random_batch(x_train, y_train)\n",
    "                    with tf.GradientTape(persistent=True) as tape:\n",
    "                        y_pred = model(x_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    for layers, optimizer in ((lower_layers, lower_optimizer), \n",
    "                                              (upper_layers, upper_optimizer)):\n",
    "                        gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                        optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                    del tape\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))\n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status['loss'] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "                y_pred = model(x_valid)\n",
    "                status['val_loss'] = np.mean(loss_fn(y_valid, y_pred))\n",
    "                status['val_accuracy'] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "                steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print('To run this cell, please install tqdm, ipywidgets and restart jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
