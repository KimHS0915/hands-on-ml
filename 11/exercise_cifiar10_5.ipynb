{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "composed-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-circus",
   "metadata": {},
   "source": [
    "Exercise 8e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lined-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "def split_train_valid(data, split_number=5000):\n",
    "    return data[split_number:], data[:split_number]\n",
    "\n",
    "x_train, x_valid = split_train_valid(x_train_full)\n",
    "y_train, y_valid = split_train_valid(y_train_full)\n",
    "\n",
    "x_means = x_train.mean(axis=0)\n",
    "x_stds = x_train.std(axis=0)\n",
    "x_train_scaled = (x_train - x_means) / x_stds\n",
    "x_valid_scaled = (x_valid - x_means) / x_stds\n",
    "x_test_scaled = (x_test - x_means) / x_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "    for i in range(20):\n",
    "        model.add(keras.layers.Dense(100, \n",
    "                                     activation='selu', \n",
    "                                     kernel_initializer='lecun_normal'))\n",
    "    model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turkish-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'sparse_categorical_crossentropy'\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "n_epochs = 100\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=25)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('alpha_dropout_cifar10_model.h5', save_best_only=True)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "super-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.9330 - acc: 0.3157 - val_loss: 1.6867 - val_acc: 0.4024\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6391 - acc: 0.4175 - val_loss: 1.6027 - val_acc: 0.4320\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5274 - acc: 0.4576 - val_loss: 1.5454 - val_acc: 0.4550\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4474 - acc: 0.4865 - val_loss: 1.5052 - val_acc: 0.4630\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3830 - acc: 0.5080 - val_loss: 1.5044 - val_acc: 0.4836\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3294 - acc: 0.5268 - val_loss: 1.4900 - val_acc: 0.4902\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2780 - acc: 0.5451 - val_loss: 1.5006 - val_acc: 0.4850\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2316 - acc: 0.5616 - val_loss: 1.4921 - val_acc: 0.5034\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1915 - acc: 0.5768 - val_loss: 1.5010 - val_acc: 0.4944\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1490 - acc: 0.5935 - val_loss: 1.4858 - val_acc: 0.5078\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1131 - acc: 0.6050 - val_loss: 1.5285 - val_acc: 0.5022\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0743 - acc: 0.6185 - val_loss: 1.6213 - val_acc: 0.4998\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0451 - acc: 0.6289 - val_loss: 1.5714 - val_acc: 0.5166\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0147 - acc: 0.6406 - val_loss: 1.6028 - val_acc: 0.5182\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9807 - acc: 0.6519 - val_loss: 1.6595 - val_acc: 0.5030\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9527 - acc: 0.6601 - val_loss: 1.6856 - val_acc: 0.5144\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9225 - acc: 0.6711 - val_loss: 1.6892 - val_acc: 0.5070\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8939 - acc: 0.6863 - val_loss: 1.8588 - val_acc: 0.5110\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8646 - acc: 0.6938 - val_loss: 1.8286 - val_acc: 0.4966\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8448 - acc: 0.6999 - val_loss: 1.8392 - val_acc: 0.5022\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8165 - acc: 0.7085 - val_loss: 1.8179 - val_acc: 0.4996\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7911 - acc: 0.7188 - val_loss: 1.8761 - val_acc: 0.5020\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7686 - acc: 0.7280 - val_loss: 1.9780 - val_acc: 0.5096\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7472 - acc: 0.7351 - val_loss: 2.0218 - val_acc: 0.5068\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7223 - acc: 0.7431 - val_loss: 1.9578 - val_acc: 0.5030\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7001 - acc: 0.7500 - val_loss: 2.1105 - val_acc: 0.5028\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6876 - acc: 0.7560 - val_loss: 2.0563 - val_acc: 0.4954\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6635 - acc: 0.7645 - val_loss: 2.0879 - val_acc: 0.5056\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6499 - acc: 0.7688 - val_loss: 2.1642 - val_acc: 0.5038\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6246 - acc: 0.7770 - val_loss: 2.2200 - val_acc: 0.4998\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6110 - acc: 0.7817 - val_loss: 2.2707 - val_acc: 0.5066\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5922 - acc: 0.7904 - val_loss: 2.3574 - val_acc: 0.4934\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5779 - acc: 0.7953 - val_loss: 2.4335 - val_acc: 0.4966\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5665 - acc: 0.7983 - val_loss: 2.4279 - val_acc: 0.4976\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5453 - acc: 0.8079 - val_loss: 2.4473 - val_acc: 0.4928\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, \n",
    "                    epochs=n_epochs, \n",
    "                    validation_data=(x_valid_scaled, y_valid), \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "popular-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4858 - acc: 0.5078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4858381748199463, 0.5077999830245972]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('alpha_dropout_cifar10_model.h5')\n",
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "filled-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "political-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, x, n_samples=10):\n",
    "    y_probas = [mc_model.predict(x) for sample in range(n_samples)]\n",
    "    return np.mean(y_probas, axis=0)\n",
    "\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, x, n_samples=10):\n",
    "    y_probas = mc_dropout_predict_probas(mc_model, x, n_samples)\n",
    "    return np.argmax(y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "irish-burke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mc_dropout_predict_classes(mc_model, x_valid_scaled)\n",
    "acc = np.mean(y_pred == y_valid[:, 0])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-exhibition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
