{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neither-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enhanced-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['January',\n",
       " 'February',\n",
       " 'March',\n",
       " 'April',\n",
       " 'May',\n",
       " 'June',\n",
       " 'July',\n",
       " 'August',\n",
       " 'September',\n",
       " 'October',\n",
       " 'November',\n",
       " 'December']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "MONTHS = calendar.month_name[1:]\n",
    "MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "    \n",
    "    x = [MONTHS[dt.month - 1] + ' ' + dt.strftime('%d, %Y') for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fixed-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adopted-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = ''.join(sorted(set(''.join(MONTHS) + '0123456789, ')))\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "changed-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = '0123456789-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defensive-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "objective-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 20, 7075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_example[0])\n",
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mineral-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7075-09-20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_example[0])\n",
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fallen-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    x_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    x = tf.ragged.constant(x_ids, ragged_rank=1)\n",
    "    return (x + 1).to_tensor()\n",
    "\n",
    "def create_dateset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revised-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_train, y_train = create_dateset(10000)\n",
    "x_valid, y_valid = create_dateset(2000)\n",
    "x_test, y_test = create_dateset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guided-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=int32, numpy=\n",
       "array([20, 24, 32, 35, 24, 29, 22, 24, 33,  1,  5,  3,  2,  1, 10,  3, 10,\n",
       "        8])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "every-reduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-rental",
   "metadata": {},
   "source": [
    "basic seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extreme-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = y_train.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1, \n",
    "                           output_dim=embedding_size, \n",
    "                           input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation='softmax')\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "encouraging-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 8s 13ms/step - loss: 1.8040 - acc: 0.3534 - val_loss: 1.3620 - val_acc: 0.4954\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 1.2083 - acc: 0.5599 - val_loss: 1.0384 - val_acc: 0.6218\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.2340 - acc: 0.5710 - val_loss: 1.0927 - val_acc: 0.6130\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.8616 - acc: 0.6829 - val_loss: 0.7503 - val_acc: 0.7151\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6409 - acc: 0.7538 - val_loss: 0.6277 - val_acc: 0.7466\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.4652 - acc: 0.8169 - val_loss: 0.3821 - val_acc: 0.8492\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5064 - acc: 0.8149 - val_loss: 0.3457 - val_acc: 0.8672\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 15s 50ms/step - loss: 0.2698 - acc: 0.9013 - val_loss: 0.2164 - val_acc: 0.9257\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 16s 51ms/step - loss: 0.2261 - acc: 0.9366 - val_loss: 0.1368 - val_acc: 0.9637\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.0954 - acc: 0.9788 - val_loss: 0.0717 - val_acc: 0.9862\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.1977 - acc: 0.9520 - val_loss: 0.1750 - val_acc: 0.9573\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0651 - acc: 0.9899 - val_loss: 0.0398 - val_acc: 0.9951\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0272 - acc: 0.9976 - val_loss: 0.0229 - val_acc: 0.9980\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0166 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9990\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0290 - acc: 0.9958 - val_loss: 0.0137 - val_acc: 0.9991\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0087 - acc: 0.9998 - val_loss: 0.0081 - val_acc: 0.9997\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0057 - acc: 0.9999 - val_loss: 0.0058 - val_acc: 0.9998\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9999\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cognitive-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [''.join([('?' + chars)[index] for index in sequence]) \n",
    "            for sequence in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "timely-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "x_new = prepare_date_strs(['September 17, 2009', 'July 14, 1789'])\n",
    "ids = np.argmax(model.predict(x_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "solar-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-02\n",
      "1789-01-14\n"
     ]
    }
   ],
   "source": [
    "x_new = prepare_date_strs(['May 02, 2020', 'July 14, 1789'])\n",
    "ids = np.argmax(model.predict(x_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inner-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = x_train.shape[1]\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    x = prepare_date_strs(date_strs)\n",
    "    if x.shape[1] < max_input_length:\n",
    "        x = tf.pad(x, [[0, 0], [0, max_input_length - x.shape[1]]])\n",
    "    return x\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    x = prepare_date_strs_padded(date_strs)\n",
    "    ids = np.argmax(model.predict(x), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exact-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_strs(['May 02, 2020', 'July 14, 1789'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-wright",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
