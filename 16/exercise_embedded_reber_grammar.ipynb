{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-cookie",
   "metadata": {},
   "source": [
    "Exercise 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moral-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_reber_grammar = [\n",
    "    [('B', 1)],\n",
    "    [('T', 2), ('P', 3)],\n",
    "    [('S', 2), ('X', 4)],\n",
    "    [('T', 3), ('V', 5)],\n",
    "    [('X', 3), ('S', 6)],\n",
    "    [('P', 4), ('V', 6)],\n",
    "    [('E', None)]\n",
    "]\n",
    "\n",
    "embedded_reber_grammar = [\n",
    "    [('B', 1)],\n",
    "    [('T', 2), ('P', 3)],\n",
    "    [(default_reber_grammar, 4)],\n",
    "    [(default_reber_grammar, 5)],\n",
    "    [('T', 6)],\n",
    "    [('P', 6)],\n",
    "    [('E', None)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dried-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string(grammar):\n",
    "    state = 0\n",
    "    output = []\n",
    "    while state is not None:\n",
    "        index = np.random.randint(len(grammar[state]))\n",
    "        production, state = grammar[state][index]\n",
    "        if isinstance(production, list):\n",
    "            production = generate_string(grammar=production)\n",
    "        output.append(production)\n",
    "    return ''.join(output)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unusual-responsibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(default_reber_grammar), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "black-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(embedded_reber_grammar), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adequate-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = 'BEPSTVX'\n",
    "\n",
    "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
    "    good_string = generate_string(grammar)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identical-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_corrupted_string(embedded_reber_grammar), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "inclusive-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acting-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 0, 2, 4, 4, 4, 2, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_ids('BTBPTTTPPXTVPXTTVPSETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thermal-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size):\n",
    "    good_strings = [string_to_ids(generate_string(embedded_reber_grammar)) \n",
    "                    for _ in range(size // 2)]\n",
    "    bad_strings = [string_to_ids(generate_corrupted_string(embedded_reber_grammar)) \n",
    "                   for _ in range(size - (size // 2))]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    x = tf.ragged.constant(all_strings, ragged_rank=1)\n",
    "    y = np.array([[1.] for _ in range(len(good_strings))] \n",
    "                 + [[0.] for _ in range(len(bad_strings))])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assumed-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_train, y_train = generate_dataset(10000)\n",
    "x_valid, y_valid = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nearby-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int32, numpy=array([0, 4, 0, 2, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "matched-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 35s 106ms/step - loss: 0.6910 - acc: 0.5095 - val_loss: 0.6825 - val_acc: 0.5645\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 0.6678 - acc: 0.5659 - val_loss: 0.6635 - val_acc: 0.6105\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 36s 117ms/step - loss: 0.6504 - acc: 0.5766 - val_loss: 0.6521 - val_acc: 0.6110\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.6347 - acc: 0.5980 - val_loss: 0.6224 - val_acc: 0.6445\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.6054 - acc: 0.6361 - val_loss: 0.5779 - val_acc: 0.6980\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.5414 - acc: 0.7093 - val_loss: 0.4695 - val_acc: 0.7795\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.4141 - acc: 0.8207 - val_loss: 0.4368 - val_acc: 0.8050\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3068 - acc: 0.8803 - val_loss: 0.1806 - val_acc: 0.9470\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.3178 - acc: 0.8640 - val_loss: 0.2621 - val_acc: 0.9005\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.1363 - acc: 0.9566 - val_loss: 0.0652 - val_acc: 0.9880\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0910 - acc: 0.9724 - val_loss: 0.0239 - val_acc: 0.9950\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.0331 - acc: 0.9927 - val_loss: 0.0119 - val_acc: 0.9995\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 0.0021 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 8.0291e-04 - acc: 1.0000 - val_loss: 6.9651e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 5.6786e-04 - acc: 1.0000 - val_loss: 5.2039e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 4.4366e-04 - acc: 1.0000 - val_loss: 4.1727e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 3.6513e-04 - acc: 1.0000 - val_loss: 3.4832e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 3.1037e-04 - acc: 1.0000 - val_loss: 2.9888e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 2.7000e-04 - acc: 1.0000 - val_loss: 2.6196e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 2.3877e-04 - acc: 1.0000 - val_loss: 2.3287e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "embedding_size = 5\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.95, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "large-paper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability that these are Reber strings:\n",
      "\tBPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 0.04%\n",
      "\tBPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.98%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "\n",
    "x_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], \n",
    "                            ragged_rank=1)\n",
    "y_proba = model.predict(x_test)\n",
    "print('Estimated probability that these are Reber strings:')\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(f'\\t{string}: {y_proba[index][0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-replica",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
