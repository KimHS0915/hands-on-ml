{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latter-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stock-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arbitrary-boards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assumed-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
    "for id_, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
    "    id_to_word[id_] = token\n",
    "' '.join([id_to_word[id_] for id_ in x_train[0][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elder-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load('imdb_reviews', as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "foster-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test', 'unsupervised'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passive-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = info.splits['train'].num_examples\n",
    "test_size = info.splits['test'].num_examples\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nutritional-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Moun ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful perf ...\n",
      "Label: 1 = Positive\n",
      "\n",
      "Review: As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursu ...\n",
      "Label: 1 = Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in datasets['train'].batch(5).take(1):\n",
    "    for review, label in zip(x_batch.numpy(), y_batch.numpy()):\n",
    "        print(f'Review: {review.decode(\"utf-8\")[:200]} ...')\n",
    "        print(f'Label: {label}', '= Positive' if label else '= Negative')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atomic-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_batch, y_batch):\n",
    "    x_batch = tf.strings.substr(x_batch, 0, 300)\n",
    "    x_batch = tf.strings.regex_replace(x_batch, rb'<br\\s*/?>', b' ')\n",
    "    x_batch = tf.strings.regex_replace(x_batch, b\"[^a-zA-Z']\", b' ')\n",
    "    x_batch = tf.strings.split(x_batch)\n",
    "    return x_batch.to_tensor(default_value=b'<pad>'), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handmade-episode",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 59), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Cons', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>'],\n",
       "        [b'Mann', b'photographs', b'the', b'Alberta', b'Rocky',\n",
       "         b'Mountains', b'in', b'a', b'superb', b'fashion', b'and',\n",
       "         b'Jimmy', b'Stewart', b'and', b'Walter', b'Brennan', b'give',\n",
       "         b'enjoyable', b'performances', b'as', b'they', b'always',\n",
       "         b'seem', b'to', b'do', b'But', b'come', b'on', b'Hollywood',\n",
       "         b'a', b'Mountie', b'telling', b'the', b'people', b'of',\n",
       "         b'Dawson', b'City', b'Yukon', b'to', b'elect', b'themselves',\n",
       "         b'a', b'marshal', b'yes', b'a', b'marshal', b'and', b'to', b'e',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'This', b'is', b'the', b'kind', b'of', b'film', b'for', b'a',\n",
       "         b'snowy', b'Sunday', b'afternoon', b'when', b'the', b'rest',\n",
       "         b'of', b'the', b'world', b'can', b'go', b'ahead', b'with',\n",
       "         b'its', b'own', b'business', b'as', b'you', b'descend', b'into',\n",
       "         b'a', b'big', b'arm', b'chair', b'and', b'mellow', b'for', b'a',\n",
       "         b'couple', b'of', b'hours', b'Wonderful', b'performances',\n",
       "         b'from', b'Cher', b'and', b'Nicolas', b'Cage', b'as', b'always',\n",
       "         b'gently', b'row', b'the', b'plot', b'along', b'There', b'are',\n",
       "         b'no', b'rapids', b'to', b'cr'],\n",
       "        [b'As', b'others', b'have', b'mentioned', b'all', b'the',\n",
       "         b'women', b'that', b'go', b'nude', b'in', b'this', b'film',\n",
       "         b'are', b'mostly', b'absolutely', b'gorgeous', b'The', b'plot',\n",
       "         b'very', b'ably', b'shows', b'the', b'hypocrisy', b'of', b'the',\n",
       "         b'female', b'libido', b'When', b'men', b'are', b'around',\n",
       "         b'they', b'want', b'to', b'be', b'pursued', b'but', b'when',\n",
       "         b'no', b'men', b'are', b'around', b'they', b'become', b'the',\n",
       "         b'pursuers', b'of', b'a', b'year', b'old', b'boy', b'And',\n",
       "         b'the', b'boy', b'becomes', b'<pad>', b'<pad>', b'<pad>']],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 1, 1], dtype=int64)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wrapped-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for x_batch, y_batch in datasets['train'].batch(32).map(preprocess):\n",
    "    for review in x_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "illegal-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "maritime-festival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "empirical-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "described-citizen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "12\n",
      "11\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
    "for word in b'This movie was faaaantastic'.split():\n",
    "    print(word_to_id.get(word) or vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "particular-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "charitable-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10771]], dtype=int64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b'This movie was faaaantastic'.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handled-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(x_batch, y_batch):\n",
    "    return table.lookup(x_batch), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opened-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets['train'].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sensitive-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  22   11   28 ...    0    0    0]\n",
      " [   6   21   70 ...    0    0    0]\n",
      " [4099 6881    1 ...    0    0    0]\n",
      " ...\n",
      " [  22   12  118 ...  331 1047    0]\n",
      " [1757 4101  451 ...    0    0    0]\n",
      " [3365 4392    6 ...    0    0    0]], shape=(32, 60), dtype=int64)\n",
      "tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_set.take(1):\n",
    "    print(x_batch)\n",
    "    print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distant-physiology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 16s 15ms/step - loss: 0.6560 - acc: 0.5852\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.4482 - acc: 0.7914\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.3206 - acc: 0.8666\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.2098 - acc: 0.9217\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1451 - acc: 0.9498\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "patent-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 22s 22ms/step - loss: 0.5374 - acc: 0.7186\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3425 - acc: 0.8575\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1970 - acc: 0.9296\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1439 - acc: 0.9489\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1112 - acc: 0.9596\n"
     ]
    }
   ],
   "source": [
    "# using masking\n",
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, \n",
    "                           embed_size, input_shape=[None], \n",
    "                           mask_zero=True),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "geographic-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 21s 22ms/step - loss: 0.5336 - acc: 0.7244\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3454 - acc: 0.8572\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1980 - acc: 0.9288\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1473 - acc: 0.9468\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1174 - acc: 0.9565\n"
     ]
    }
   ],
   "source": [
    "# using manual masking\n",
    "\n",
    "K = keras.backend\n",
    "embed_size = 128\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(z)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-glass",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
