{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671e9a22",
   "metadata": {},
   "source": [
    "Exercise 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ead668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFOpenAIGPTLMHeadModel.\n",
      "\n",
      "All the layers of TFOpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-gpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFOpenAIGPTLMHeadModel\n",
    "\n",
    "model = TFOpenAIGPTLMHeadModel.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c455ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTTokenizer\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa18e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = 'This royal throne of kings, this sceptred isle'\n",
    "encoded_prompt = tokenizer.encode(prompt_text, \n",
    "                                  add_special_tokens=False, \n",
    "                                  return_tensors='tf')\n",
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c24a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   239,   568,   895,   587,   600,   966,   525,  2455,\n",
       "          500,   481,   929,  1082,   257,   256, 40477,   256,  3369,\n",
       "          600,   587,   538,   823,   704,  3354,   498,   688,   240,\n",
       "          256,   481,  1002,   603,   239, 40477,   256,   249,  1259,\n",
       "          799,   651,   485,   547,  1158],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   267,   485,   925,   575,  4385,   240,   512,   759,\n",
       "          595,   239,   568,   606,   604,   485,   825,   498,   575,\n",
       "          267,   488,   507,  1259,   580,  1256,  6465,   239,   507,\n",
       "          544,   595,   870,   525,  1288,  1175, 20128,   481,   618,\n",
       "          498,   481, 34251,  7455,   240],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   240,   498,   589,  3142,   240,   488,   616,  1813,\n",
       "          240,  4931,  1246,   507,   485,   510,   240,   488,   616,\n",
       "          889,   260, 16934,  2399,   498,   481,  3016,   240,   620,\n",
       "          525,   861,   525,  1203,  2268,   249,  1063,  2071,   485,\n",
       "        11818,   500,   547,  1074,   638],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   239,   645,   775,   566,   498,  1288, 26648, 21465,\n",
       "          558,   899,   551,   485,   580, 12805,   240,   481,   867,\n",
       "         8686,   498,   616,  1424,  7037,   636,   604,  3405,   507,\n",
       "          488,  2055, 11093,   525,  7339,   239,   606,   699,   525,\n",
       "          481,  5751,  6404,   509,   481],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   980,  1120,   694,   481,   929,  1082,   487,   885,\n",
       "         3087,   556,   524,  5353, 21443,   240,   488,   507,   544,\n",
       "          481,  2576,   498,   524,  6391,  1712,   240,   618,  3786,\n",
       "          753,   240,   763,   929, 25475,   507,   239,   512,   812,\n",
       "          604,  1172,   498,  3786,   753]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences = 5\n",
    "length = 40\n",
    "\n",
    "generated_sequences = model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    do_sample=True,\n",
    "    max_length=length + len(encoded_prompt[0]),\n",
    "    temperature=1.0,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    num_return_sequences=num_sequences,\n",
    ")\n",
    "\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa21923f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this royal throne of kings, this sceptred isle. but why do they need that tree in the first place?'\n",
      "'surely they don't want your knowledge of them,'the voice said. \n",
      "'i must go back to my father\n",
      "----------------------------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle! to make him stronger, you can not. but we have to think of him! and it must be done swiftly. it is not good that these men slay the king of the accursed empire,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle, of all places, and this ring, whoever gave it to me, and this much - priceless piece of the queen, so that after that three months i might speak to thee in my own way\n",
      "----------------------------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle. if any one of these pretentious estates had turned out to be worthless, the two leaders of this great nation would have claimed it and completely ruled that kingdom. we know that the royal throne was the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle has always been the first place he made contact with his former conquest, and it is the site of his twin brother, king astel, who first commissioned it. you will have heard of astel\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sequence in generated_sequences:\n",
    "    text = tokenizer.decode(sequence, clean_up_tokenization_sapeces=True)\n",
    "    print(text)\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95493f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hands] *",
   "language": "python",
   "name": "conda-env-hands-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
