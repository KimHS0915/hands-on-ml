{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formal-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "burning-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "x_train = series[:7000, :n_steps]\n",
    "x_valid = series[7000:9000, :n_steps]\n",
    "x_test = series[9000:, :n_steps]\n",
    "\n",
    "y = np.empty((10000, n_steps, 10))\n",
    "\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\n",
    "\n",
    "y_train = y[:7000]\n",
    "y_valid = y[7000:9000]\n",
    "y_test = y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hindu-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(y_true, y_pred):\n",
    "    return keras.metrics.mean_squared_error(y_true[:, -1], y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-basic",
   "metadata": {},
   "source": [
    "Deep RNN with Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "former-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 33s 145ms/step - loss: 0.1929 - last_time_step_mse: 0.1902 - val_loss: 0.0877 - val_last_time_step_mse: 0.0832\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 31s 142ms/step - loss: 0.0537 - last_time_step_mse: 0.0449 - val_loss: 0.0549 - val_last_time_step_mse: 0.0462\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 30s 139ms/step - loss: 0.0471 - last_time_step_mse: 0.0375 - val_loss: 0.0451 - val_last_time_step_mse: 0.0358\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 28s 127ms/step - loss: 0.0437 - last_time_step_mse: 0.0337 - val_loss: 0.0418 - val_last_time_step_mse: 0.0314\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 29s 134ms/step - loss: 0.0409 - last_time_step_mse: 0.0306 - val_loss: 0.0391 - val_last_time_step_mse: 0.0287\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 29s 134ms/step - loss: 0.0385 - last_time_step_mse: 0.0275 - val_loss: 0.0379 - val_last_time_step_mse: 0.0273\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 30s 139ms/step - loss: 0.0366 - last_time_step_mse: 0.0254 - val_loss: 0.0367 - val_last_time_step_mse: 0.0248\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 27s 126ms/step - loss: 0.0349 - last_time_step_mse: 0.0235 - val_loss: 0.0363 - val_last_time_step_mse: 0.0249\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 27s 125ms/step - loss: 0.0338 - last_time_step_mse: 0.0221 - val_loss: 0.0332 - val_last_time_step_mse: 0.0208\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 29s 133ms/step - loss: 0.0329 - last_time_step_mse: 0.0214 - val_loss: 0.0335 - val_last_time_step_mse: 0.0214\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 29s 134ms/step - loss: 0.0322 - last_time_step_mse: 0.0206 - val_loss: 0.0323 - val_last_time_step_mse: 0.0203\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 28s 130ms/step - loss: 0.0316 - last_time_step_mse: 0.0198 - val_loss: 0.0333 - val_last_time_step_mse: 0.0210\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 28s 130ms/step - loss: 0.0310 - last_time_step_mse: 0.0191 - val_loss: 0.0310 - val_last_time_step_mse: 0.0187\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 30s 137ms/step - loss: 0.0305 - last_time_step_mse: 0.0186 - val_loss: 0.0310 - val_last_time_step_mse: 0.0189\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 30s 135ms/step - loss: 0.0302 - last_time_step_mse: 0.0182 - val_loss: 0.0298 - val_last_time_step_mse: 0.0178\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 30s 135ms/step - loss: 0.0296 - last_time_step_mse: 0.0176 - val_loss: 0.0293 - val_last_time_step_mse: 0.0174\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 28s 126ms/step - loss: 0.0293 - last_time_step_mse: 0.0172 - val_loss: 0.0315 - val_last_time_step_mse: 0.0200\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 28s 130ms/step - loss: 0.0289 - last_time_step_mse: 0.0168 - val_loss: 0.0295 - val_last_time_step_mse: 0.0174\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 28s 126ms/step - loss: 0.0286 - last_time_step_mse: 0.0168 - val_loss: 0.0290 - val_last_time_step_mse: 0.0163\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 29s 134ms/step - loss: 0.0281 - last_time_step_mse: 0.0161 - val_loss: 0.0288 - val_last_time_step_mse: 0.0164\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, input_shape=[None, 1], \n",
    "                           return_sequences=True),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', \n",
    "              optimizer='adam', \n",
    "              metrics=[last_time_step_mse])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-driving",
   "metadata": {},
   "source": [
    "Deep RNNs with Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entire-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization\n",
    "\n",
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation='tanh', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, \n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "played-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 67s 294ms/step - loss: 0.1594 - last_time_step_mse: 0.1521 - val_loss: 0.0735 - val_last_time_step_mse: 0.0624\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 64s 294ms/step - loss: 0.0635 - last_time_step_mse: 0.0508 - val_loss: 0.0561 - val_last_time_step_mse: 0.0415\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 64s 291ms/step - loss: 0.0527 - last_time_step_mse: 0.0364 - val_loss: 0.0498 - val_last_time_step_mse: 0.0328\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 64s 293ms/step - loss: 0.0466 - last_time_step_mse: 0.0307 - val_loss: 0.0440 - val_last_time_step_mse: 0.0288\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 64s 294ms/step - loss: 0.0423 - last_time_step_mse: 0.0276 - val_loss: 0.0410 - val_last_time_step_mse: 0.0252\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 65s 295ms/step - loss: 0.0389 - last_time_step_mse: 0.0241 - val_loss: 0.0373 - val_last_time_step_mse: 0.0218\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 64s 290ms/step - loss: 0.0372 - last_time_step_mse: 0.0224 - val_loss: 0.0358 - val_last_time_step_mse: 0.0209\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 64s 293ms/step - loss: 0.0349 - last_time_step_mse: 0.0201 - val_loss: 0.0336 - val_last_time_step_mse: 0.0185\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 65s 296ms/step - loss: 0.0329 - last_time_step_mse: 0.0186 - val_loss: 0.0318 - val_last_time_step_mse: 0.0175\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 65s 295ms/step - loss: 0.0318 - last_time_step_mse: 0.0182 - val_loss: 0.0308 - val_last_time_step_mse: 0.0165\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 65s 295ms/step - loss: 0.0307 - last_time_step_mse: 0.0171 - val_loss: 0.0297 - val_last_time_step_mse: 0.0162\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 63s 289ms/step - loss: 0.0298 - last_time_step_mse: 0.0166 - val_loss: 0.0289 - val_last_time_step_mse: 0.0157\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 64s 292ms/step - loss: 0.0289 - last_time_step_mse: 0.0157 - val_loss: 0.0282 - val_last_time_step_mse: 0.0152\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 65s 297ms/step - loss: 0.0284 - last_time_step_mse: 0.0156 - val_loss: 0.0275 - val_last_time_step_mse: 0.0148\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 64s 292ms/step - loss: 0.0279 - last_time_step_mse: 0.0153 - val_loss: 0.0272 - val_last_time_step_mse: 0.0149\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 64s 294ms/step - loss: 0.0273 - last_time_step_mse: 0.0148 - val_loss: 0.0273 - val_last_time_step_mse: 0.0147\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 65s 295ms/step - loss: 0.0267 - last_time_step_mse: 0.0143 - val_loss: 0.0260 - val_last_time_step_mse: 0.0134\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 64s 294ms/step - loss: 0.0262 - last_time_step_mse: 0.0140 - val_loss: 0.0257 - val_last_time_step_mse: 0.0135\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 65s 297ms/step - loss: 0.0258 - last_time_step_mse: 0.0137 - val_loss: 0.0254 - val_last_time_step_mse: 0.0130\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 65s 295ms/step - loss: 0.0252 - last_time_step_mse: 0.0129 - val_loss: 0.0248 - val_last_time_step_mse: 0.0122\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), input_shape=[None, 1], \n",
    "                           return_sequences=True),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', \n",
    "              optimizer='adam', \n",
    "              metrics=[last_time_step_mse])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-strap",
   "metadata": {},
   "source": [
    "Creating a Custom RNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compliant-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.layers.Layer):\n",
    "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "        self.get_initial_state = getattr(\n",
    "            self.cell, 'get_initial_state', self.fallback_initial_state)\n",
    "        \n",
    "    def fallback_initial_state(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        states = self.get_initial_state(inputs)\n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size = shape[0]\n",
    "        n_steps = shape[1]\n",
    "        sequences = tf.TensorArray(\n",
    "            inputs.dtype, size=(n_steps if self.return_sequences else 0))\n",
    "        outputs = tf.zeros(shape=[batch_size, self.cell.output_size], dtype=inputs.dtype)\n",
    "        for step in tf.range(n_steps):\n",
    "            outputs, states = self.cell(inputs[:, step], states)\n",
    "            if self.return_sequences:\n",
    "                sequences = sequences.write(step, outputs)\n",
    "        if self.return_sequences:\n",
    "            return tf.transpose(sequences.stack(), [1, 0, 2])\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educational-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 67s 303ms/step - loss: 0.1597 - last_time_step_mse: 0.1569 - val_loss: 0.0743 - val_last_time_step_mse: 0.0717\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 65s 297ms/step - loss: 0.0643 - last_time_step_mse: 0.0538 - val_loss: 0.0573 - val_last_time_step_mse: 0.0427\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 66s 299ms/step - loss: 0.0535 - last_time_step_mse: 0.0396 - val_loss: 0.0504 - val_last_time_step_mse: 0.0338\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 65s 297ms/step - loss: 0.0468 - last_time_step_mse: 0.0313 - val_loss: 0.0442 - val_last_time_step_mse: 0.0306\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 63s 288ms/step - loss: 0.0423 - last_time_step_mse: 0.0279 - val_loss: 0.0409 - val_last_time_step_mse: 0.0260\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 63s 289ms/step - loss: 0.0389 - last_time_step_mse: 0.0244 - val_loss: 0.0368 - val_last_time_step_mse: 0.0217\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 64s 294ms/step - loss: 0.0364 - last_time_step_mse: 0.0221 - val_loss: 0.0346 - val_last_time_step_mse: 0.0199\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 66s 302ms/step - loss: 0.0343 - last_time_step_mse: 0.0203 - val_loss: 0.0333 - val_last_time_step_mse: 0.0190\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 71s 325ms/step - loss: 0.0329 - last_time_step_mse: 0.0191 - val_loss: 0.0340 - val_last_time_step_mse: 0.0194\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 71s 327ms/step - loss: 0.0322 - last_time_step_mse: 0.0183 - val_loss: 0.0311 - val_last_time_step_mse: 0.0168\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 70s 318ms/step - loss: 0.0309 - last_time_step_mse: 0.0173 - val_loss: 0.0301 - val_last_time_step_mse: 0.0166\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 70s 319ms/step - loss: 0.0299 - last_time_step_mse: 0.0167 - val_loss: 0.0289 - val_last_time_step_mse: 0.0155\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 71s 326ms/step - loss: 0.0290 - last_time_step_mse: 0.0158 - val_loss: 0.0283 - val_last_time_step_mse: 0.0149\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 73s 332ms/step - loss: 0.0284 - last_time_step_mse: 0.0156 - val_loss: 0.0276 - val_last_time_step_mse: 0.0147\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 73s 331ms/step - loss: 0.0278 - last_time_step_mse: 0.0149 - val_loss: 0.0271 - val_last_time_step_mse: 0.0141\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 70s 319ms/step - loss: 0.0274 - last_time_step_mse: 0.0148 - val_loss: 0.0279 - val_last_time_step_mse: 0.0150\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 70s 320ms/step - loss: 0.0267 - last_time_step_mse: 0.0140 - val_loss: 0.0261 - val_last_time_step_mse: 0.0133\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 69s 317ms/step - loss: 0.0263 - last_time_step_mse: 0.0136 - val_loss: 0.0257 - val_last_time_step_mse: 0.0133\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 71s 323ms/step - loss: 0.0258 - last_time_step_mse: 0.0134 - val_loss: 0.0258 - val_last_time_step_mse: 0.0141\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 67s 306ms/step - loss: 0.0253 - last_time_step_mse: 0.0127 - val_loss: 0.0248 - val_last_time_step_mse: 0.0125\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    MyRNN(LNSimpleRNNCell(20), input_shape=[None, 1], \n",
    "                           return_sequences=True),\n",
    "    MyRNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', \n",
    "              optimizer='adam', \n",
    "              metrics=[last_time_step_mse])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
